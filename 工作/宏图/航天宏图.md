算法模型上传目录：213-`/data/imagedata/work/`

前端上传目录：213-`/pie/data/servicedata/webapps/dist`



1、对加密软件的使用。
2、对项目进行备份更新回滚输出日志等操作

- 备份标准
  - 文件修改：使用`mv`命令将文件名字设置为`.bak`形式。 例如：`mv xjar.go xjar.go.bak`
  - 内容是使用`cp`命令将文件名字后面的`.bak`删除即可 例如：`cp xjar.go.bak xjar.go`
- 使用 `前者 > 后者` 命令生成一个日志。

3、线程池的使用
4、Hibernate
5、postgresql

# 2024/5/15
## 替换镜像提交到harbor

- 212是server系统

- 213是factory系统

1. 对镜像进行加载

   ```docker
   docker load -i security-auth-service.tar.gz
   ```

   > - `docker load -i` 更直接地指定了文件路径作为参数。
   > - `docker load <` 则是通过shell重定向来隐式地提供文件内容作为输入。

   结果如下：

   `Loaded image: server/security-auth-service:v1`
   这里有可能会遇见结果是id的情况
   `Loaded image ID: sha256:ac0bd22f27ee443bf766dabd8ef8b460b972bc8b1bdb461cc241acb7afb21db8`
   这个就直接将ID：后面的当成镜像名字改了就行了。操作一样

   > 镜像名字是后面的 `server/security-auth-service:v1`

2. 对镜像名字进行修改
   ```docker
   docker tag server/security-auth-service:v1 127.0.0.212:1180/server/security-auth-service:v1
   ```

   > 这里的`127.0.0.212:1180`是通过使用命令`docker images`来进行查看的，在镜像的开头就是服务器
   >
   > 注意：这里自动带了/server，这个前缀需要有。
   
3. 对镜像进行上传
   ```docker
   docker push 127.0.0.212:1180/server/security-auth-service:v1
   ```

4. k8s删除原有的pod

   ```k8s
   kubectl delete pods security-auth-service-84b7c7bb4c-bx664 -n pie-engine-server
   ```

   > 这个删除完之后会自动创建新的pod,进行重启

5. 查看所有pod获取新的pod名称 
   ```k8s
   kubectl get pods [-A / -n pie-engine-server]
   ```

   > 这个获取新的pod名称可以通过时间来进行获取
   >
   > 通过这个命令查看新启动的pod是否正常。

6. 通过新的pod名称来进行查看日志或者

   ```k8s
   kubectl logs 重启后的pod名称 -n pie-engine-server
   ```

   > - 这个命令用于查看一个或多个容器的stdout 和 stderr 输出，即容器的标准输出和标准错误流。
   > - 当你想要检查应用程序的日志，以诊断问题或理解应用程序的行为时，通常会使用这个命令

   ```k8s
   kubectl describe pods 重启后的pod名称 -n pie-engine-server
   ```

   > - 这个命令提供了一个详细的视图，包括 pod 的配置、状态、事件、IP 地址、节点信息、容器镜像以及其他相关元数据。
   > - 它不仅显示 pod 内每个容器的日志摘要（如果有），还显示了 pod 的完整生命周期信息，比如创建时间、启动和停止事件、重启策略等





## 修改了yaml文件之后需要操作 && 重启服务

> 如果重启一个服务直接delete和apply即可。

1. 进行提交

   ```k8s
   kubectl delete -f security-auth-server.yaml
   ```

   > 可以先删除再提交，也可以直接提交

   ```k8s
   kubectl apply -f security-auth-server.yaml
   ```

2. 获取相应的pods
   ```k8s
   kubectl get pods -n pie-engine-server
   ```

   详细查看pods

   ```k8s
   kubectl describe pods security-auth-service-84dbd6b75-gwx7g -n pie-engine-server
   ```

   查看logs

   ```k8s
   kubectl logs security-auth-service-84dbd6b75-gwx7g -n pie-engine-server
   ```






## 对`no space left on device`的处理

场景：

```docker
[root@master home]# docker load -i security-auth-service.tar.gz
mkdir /data/docker/tmp/docker-import-597606404: no space left on device

[root@master home]# docker rmi -f server/security-auth-service
Error: No such image: server/security-auth-service

[root@master home]# docker rmi -f server/security-auth-service:v1
Error response from daemon: open /data/docker/image/overlay2/.tmp-repositories.json745161134: no space left on device
```

> 出现错误`no space left on device`
>
> 这是因为iNode满了，iNode相当于索引，存储文件的源信息，具体原因一般都是小文件太多导致的，服务器上原因是因为进行了切片导致了小文件太多了，将索引占完了。
>
> 附加：
>
> 这个因为有个定时任务，所以说需要将定时任务先删除。

解决方案： 

使用`df -i`查看一下相应的利用率，看谁的高，然后利用命令

```shell
for i in /data/sharefile/objects/*; do echo $i; find $i | wc -l; done
```

> 这里需要明白的是`in`后面的是自己需要查看的目录

打印目录下文件数目，一层一层向下走，直到找到相应的切片目录，如果可以删除就删了。

## 使用nfs进行局域网内两台服务器文件共享

是再`212服务器`上面的`/home/share`文件夹共享到`213服务器`上的`/data/imagedata/share`

```shell
-- 212 
rpm -qa nfs-utils rpcbind

systemctl status nfs

mkdir -p /home/share chmod 777 /home/share

vim /etc/exports
// 需要输入下面的数据
/home/share 172.16.154.213(rw,sync,insecure,no_subtree_check,no_root_squash)

保存后 systemctl start rpcbind

systemctl start nfs

systemctl status nfs

cat   /etc/exports

ln -s /home/share /data/sharefile/share




-- 213

mkdir /data/imagedata/share

mount 127.0.0.212:/home/share  /data/imagedata/share

ll /data/imagedata/share

```



```
3、配置nfs客户端和服务端
nfs服务配置
nfs服务端
找1台机器作为nfs服务端（如：服务端机器ip：172.16.40.18）
1).创建数据目录  
mkdir -p /nfs_data
2).配置共享目录允许客户端访问
vi /etc/exports
/nfs_data 172.16.40.18(rw,sync,no_root_squash)
/nfs_data 172.16.40.19(rw,sync,no_root_squash)
/nfs_data 172.16.40.20(rw,sync,no_root_squash)

注：exportfs –rv
3).启动nfs服务
systemctl start rpcbind
systemctl start nfs

nfs客户端服务端NFS
启动nfs服务
systemctl start rpcbind
systemctl start nfs
1).查看服务共享目录
showmount -e 172.16.40.18 

2).客户端创建本地目录 
mkdir -p pie/data

3).挂载共享目录
mount -t nfs 172.16.40.18:/nfs_data /pie/data

4).查看挂载结果
df -h 

5).设置开机启动自动挂载nfs
chkconfig --level 35 nfs on
vi /etc/fstab
172.16.40.18:/nfs_data  /pie/data  nfs  defaults  0 0

```







# 2024/5/16





## 重启所有服务

```shell
cd /home/server/scripts
sh restart_app.sh
cd /home/server/scripts/help
sh 1_restart_bpaas_server.sh
如果scripts下没有help则手动执行下面两个命令
v3.4.5之后下面的脚本都不需要执行了。
重启完所有服务之后因为中间件顺序问题
需要做：
\#重启bpaas
kubectl get pod -n pie-engine-bpaas | awk '{print $1}' | xargs kubectl delete pod -n pie-engine-bpaas
\#重启server，后于bpaas几秒启动，因为注册，确定bpaas重启完执行下面
kubectl get pod -n pie-engine-server | awk '{print $1}' | xargs kubectl delete pod -n pie-engine-server
```







## job查看

```shell
kjob get pod|grep Running 
```

> 查询正在运行的job





## 重启harbor



```shell
#harbor目录一般在这儿 根据global.yaml来的
cd /home/server/depends/harbor
#查状态
docker-compose ps
#停harbor
docker-compose down
#启动harbor
docker-compose up -d
#验证
登录http://ip:1180
能访问到登录页面即可

或者看下能否登陆成功
执行这个 restart_harbor.sh
docker login 你的ip:1180
账号 admin

看下能否登陆成功

-----------------------------------------------------------------------
#查harbor日志
/var/log/harbor
tail -f postgresql.log
#harbor数据目录 根据global.yaml来的
cd /data/harbor/database
chmod 750 pg13
```



# 2024/5/20

## 锁

# 2024/5/21

## 线程池

线程池的使用场景：

1、异步使用。

2、进行推送，如百万级数据推送。

[【博客】线程池的使用_阅读数_bilibili](https://www.bilibili.com/video/BV1bh411a7SE/?p=2)

[线程在实际项目中的应用场景，可用于面试，十年大厂程序员讲解，通俗易懂](https://www.bilibili.com/video/BV16g41177Pw/?share_source=copy_web&vd_source=a9e0245042931de24eb0a8f018fa0eae)



# 2024/5/23

## 测试接口在服务器上通没通

>  可以直接在linux服务器上面用 telnet IP 端口 命令看看端口通不通，或者用curl命令看看url地址能不能访问

```shell
curl -X POST http://192.168.1.1:8083/kfpt/openapi/getApiToken
```



```shell
curl http://192.168.1.1/OneMapServer/rest/services/sat_2013/MapServer
```



```shell
ping 192.168.1.1
```



```shell
telnet 192.168.1.1 80
```





# 2024/5/28

## 文档能力

着重注意文档，文档能力必须要整理好，不然到之后还得麻烦自己。



# 2024/5/31

## 对数据进行处理

```sql
INSERT INTO production_entity (
    zt_code,
    zt_type,
    name,
    latitude,
    longitude,
    area,
    create_time,
    update_time,
    region_name,
    region_code
)
WITH subquery AS (
    SELECT
        t.zt_code,
        t.zt_type,
        t.zt_name,
        t.farm_center_lat,
        t.farm_center_lng,
        COALESCE(SUM(area), 0) AS total_area
    FROM
        rice_planter_info t
    GROUP BY
        t.zt_code,
        t.zt_type,
        t.zt_name,
        t.farm_center_lat,
        t.farm_center_lng
)
SELECT
    subquery.zt_code,
    subquery.zt_type,
    subquery.zt_name,
    subquery.farm_center_lat,
    subquery.farm_center_lng,
    subquery.total_area,
    NOW() AS create_time,
    NOW() AS update_time,
    rp.county_name,
    sr.region_code
FROM
    subquery
LEFT JOIN rice_plant_info rp ON subquery.zt_code = rp.zt_code
JOIN sys_region sr ON sr.region_name = rp.county_name;
-- 这里会有重复数据，来源于JOIN rice_plant_info rp ON subquery.zt_code = rp.zt_code
```

> 这里会有重复数据，因为主表subquery和子表rice_plant_info的数据是一对多的关系，所以说会重复，如果想要不重复。需要进行修改
>



```sql
INSERT INTO production_entity (
    zt_code,
    zt_type,
    name,
    latitude,
    longitude,
    area,
    create_time,
    update_time,
    region_name,
    region_code
)
(
select d.*,sr.region_code,sr.region_name from 
(SELECT
        t.zt_code,
        t.zt_type,
        t.zt_name,
        t.farm_center_lat,
        t.farm_center_lng,
        COALESCE(SUM(area), 0) AS total_area,
		NOW() AS create_time,
		NOW() AS update_time
    FROM
        rice_planter_info t
    GROUP BY
        t.zt_code,
        t.zt_type,
        t.zt_name,
        t.farm_center_lat,
        t.farm_center_lng ) d 
left join  (select DISTINCT zt_code,county_name from rice_plant_info) rp ON d.zt_code = rp.zt_code and rp.zt_code is not null
LEFT JOIN sys_region sr ON sr.region_name = rp.county_name
)
```

> 这里是修改过之后的，有两个问题，一是使用了经纬度分组，会有脏数据，需要处理。
>
> 逻辑是通过分组查询rice_planter_info的相应数据，然后left join进行左连接连接rice_plant_info通过zt_code获取county_name然后通过county_name来联表region获取区域和区域代码。
>



这里有重复数据，进行筛洗

原始数据不必理会

```sql
select * from production_entity where latitude is null and zt_code in(
select p.zt_code from production_entity p GROUP BY p.zt_code HAVING COUNT(1) > 1
) ORDER BY zt_code
```

> 逻辑是通过分组查询重复的，然后进行查询经纬度为null的值。
>
> 查完之后进行删除。将查询到的数据根据id进行两者数据累加



# 2024/6/4

## SpringSecurity

功能

**身份认证**：·身份认证是验证谁正在访问系统资源，判断用户是否为合法用户。认证用户的常见方式是要求用户输入用户名和密码

**授权**：用户进行身份认证后，系统会控制谁能访问哪些资源，这个过程叫做授权。用户无法访问没有权限的资源。

**防御常见攻击**：

- CSRF

- HTTP Headers
- HTTP Requests



SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。这里我们可以看看入门案例中的过滤器。

- **UsernamePasswordAuthenticationFilter**：负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。

- **ExceptionTranslationFilter**:处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException

- **FilterSecuritylnterceptor**：负责权限校验的过滤器。



**Authentication**接口: 它的实现类，表示当前访问系统的用户，封装了用户相关信息。

**AuthenticationManager**接口：定义了认证Authentication的方法

**UserDetailsService**接口：加载用户特定数据的核心接口。里面定义了一个根据用户名查询用户信息的方法。

**UserDetails**接口：提供核心用户信息。通过UserDetailsService根据用户名获取处理的用户信息要封装成UserDetails对象返回。然后将这些信息封装到Authentication对象中。













**具体使用：**

1、百度添加依赖

2、需要添加一个配置类，具体去[spring官网](https://docs.spring.io/spring-security/reference/servlet/configuration/java.html)上进行配置类配置。

3、基于数据库的用户认证流程实现。

4、



**基于数据库的用户认证流程实现**：

[14-自定义配置-基于数据库的用户认证流程实现_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV14b4y1A7Wz?p=14)

- 程序启动时：
  - 创建DBUserDetailsManager类，实现接口UserDetailsManager,UserDetailsPasswordService。
  - 在应用程序中初始化这个类的对象

> 第一步主要是将内存中的配置放入到表中。这里是需要修改一下具体使用的配置，具体可以参照`InMemoryUserDetailsManager`这个方法中返回值等东西
>
> 其中主要是loadUserByUsername重写方式需要参考

重写详情

![image-20240604174043250](assets/image-20240604174043250.png)

重写后的配置类

![image-20240604174153000](assets/image-20240604174153000.png)

这个DBUserByUsername就是实现继承的方法

关于初始化类：这里面可以不在配置类中添加，直接再DBUserByUsername类中添加Component注解然后删除这个配置类都行，因为security实行的是







## OAuth 2.0

>  主要是为了解决授权和安全相关的问题的，如防止第三方破解密码
>
> 场景是如果用户需要进行pdf打印

![image-20240604104820562](assets/image-20240604104820562.png)

> 一般来说就是这四种角色，用户，客户应用，第三方授权服务器，资源服务器（后端） 
>
> 这里面1是微信登陆，2是redirect。5之前应该有一个下发授权码，然后客户应用使用授权码进行申请token,看下图

![](assets/OAuth.png)



OAuth2提供**授权码模式**、**密码模式**、**简化模式**、**客户端模式**等四种授权模式。[41-OAuth2-四种授权模式-授权码模式_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV17M4m1R7WG?p=41)

- #### 第一种方式：授权码

  **授权码（authorization code），指的是第三方应用先申请一个授权码，然后再用该码获取令牌。**

  这种方式是最常用，最复杂，也是最安全的，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。

  

  ![image-20231220180422742](assets/image-20231220180422742-1717572807604-1.png)

  - 注册客户应用：客户应用如果想要访问资源服务器需要有凭证，需要在授权服务器上注册客户应用。注册后会**获取到一个ClientID和ClientSecrets**

    这两个是应用访问id和应用访问密钥

  #### 第二种方式：隐藏式

  **隐藏式（implicit），也叫简化模式，有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端。**

  RFC 6749 规定了这种方式，允许直接向前端颁发令牌。这种方式没有授权码这个中间步骤，所以称为隐藏式。这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。

  ![image-20231220185958063](assets/image-20231220185958063-1717572822222-3.png)

  ```
  https://a.com/callback#token=ACCESS_TOKEN
  将访问令牌包含在URL锚点中的好处：锚点在HTTP请求中不会发送到服务器，减少了泄漏令牌的风险。
  ```

  

  

  #### 第三种方式：密码式

  **密码式（Resource Owner Password Credentials）：如果你高度信任某个应用，RFC 6749 也允许用户把用户名和密码，直接告诉该应用。该应用就使用你的密码，申请令牌。**

  这种方式需要用户给出自己的用户名/密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。

  ![image-20231220190152888](assets/image-20231220190152888-1717572832053-5.png)

  #### 第四种方式：凭证式

  **凭证式（client credentials）：也叫客户端模式，适用于没有前端的命令行应用，即在命令行下请求令牌。**

  这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。

  ![image-20231220185958063](assets/image-20231220185958063-1717572867573-7.png)

授权类型选择

![image-20231223020052999](assets/image-20231223020052999.png)

> 第一方：企业内部的。
>
> 第二方：甲方或者第三方

**Oauth2:**

是一种安全的授权框架，提供了一套详细的授权机制。用户或应用可以通过公开的或私有的设置，授权第三方应用访问特定资源。它详细描述了系统中不同角色、用户、服务前端应用（比如API），以及客户端（比如网站或移动App）之间怎么实现相互认证。

Oauth2定义了一组想当复杂的规范。涉及到：Roles角色、Client Types客户端类型、ClientProfile客户端描述、Authorization Grants认证授权、Endpoints终端等。

**JWT:**

提供了一种用于发布接入令牌（Access Token),并对发布的签名接入令牌进行验证的方法。令牌（Token）本身包含了一系列声明，应用程序可以根据这些声明限制用户对资源的访问。

总结：Oauth2是一个规范，大概流程是上面的那个图，JWT是实现授权服务器中的AccessToken一个方法而已同。





**应用场景**：

需要三方认证的时候才需要Oauth2.0。

如：

```text
Authorization: Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJhZG1pbiIsImV4cCI6MTU1ODk2NzY0OSwiaWF0IjoxNTU4OTQ2MDQ5fQ.jsJvqHa1tKbJazG0p9kq5J2tT7zAk5B6N_CspdOAQLWgEICStkMmvLE-qapFTtWnnDUPAjqmsmtPFSWYaH5LtA
```







## SSO（Single Sign On）

> 
>
> CAS是中央认证服务，Central Authentication Service的缩写，每个单点登录的架构都需要实现一个CAS服务
>
> 其实就是一个认证。

服务标识：每个系统或应用都会从 CAS获得一个唯一标识



TGT Ticket:是在成功通过 CAS 认证后通过 cookie 的形式发放给客户端的，可以把它比作游乐园的通票，有了它就可以畅玩游乐园中的所有项目。

Service Ticket (ST) :  有的项目需要特殊的门票，这好比是某个具体游玩项目的门票。





## 理解认证与授权

什么是认证 (Authentication)：认证是关于验证你的凭据，如用户名/邮箱和密码，以验证访问者的身份。

什么是授权（Authorization)：授权发生在系统完成身份认证之后，最终会授予你访问资源（如信息，文件，数据库，资金，位置，几乎任何内容）的完全权限。



在典型的单点登录SSO体系结构中，身份提供者和服务提供者交换数字证书和元数据以建立信任。它们通过诸如安全断言标记语言（SAML）、OIDC（基于OAuth2）等开放协议进行交互



其中OIDC = OAuth2 + 认证

- OIDC 是在 OAuth2 基础上的扩展，主要加入了认证的内容
- OAuth2中有4个角色，分别是授权服务器，资源服务器，资源所有者，客户端
- OIDC聚焦在认证环节，所以没有资源服务器这个角色，其他三个名称也做了调整，授权服务器改成了 OpenlD provider，资源所有者称作终端用户(end user)，而客户端称作 Relying party



1、OAuth2 中定义了 4 种授权方式，最常见的是授权码方式（Authorization Code），也是我们上面例子中演示的（微信登陆腾讯会议），这种方式的优点之一是我们不需要将密码告知客户端，也能让客户端获得需要的资源

2、OAuth2 中规定了两个服务接口，分别是授权接口（Authorization Endpoint）和令牌接口（token endpoint），OIDC 中新增了一个 userinfo 接口，用于获取更信息的用户信息

3、scope 定义了具体需要访问资源的内容，这并非由规范定义，而是有服务实现方决定，OIDC 中增加了 openid 的 scope，这样调用令牌接口返回的响应中就会携带openid 属性，这个 ID 是个 JWT

4、OAuth2中定义了两种令牌，访问令牌（Access token）和刷新令牌（refresh token），OIDC新增了一种令牌openid，当scope 中指定了 openid 后就会得到 openid 令牌



> scope 它定义了客户端所请求的对用户资源的访问权限范围。简而言之，`scope`是一个字符串参数，用于详细说明客户端希望获得哪些类型的访问权限。服务提供商（如授权服务器）会根据提供的`scope`来决定授予访问令牌（access token）时包含哪些权限。



# 2024/6/5

## 端口处理

`lsof -i:8000` 用`lsof`命令查看监听端口

使用 `lsof -i:端口号` 可以获得所有在指定端口号上打开的文件

使用 `lsof -i TCP/UDP` 列出使用了TCP 或 UDP 协议的文件

使用 `lsof -i TCP:3306` 列出使用了TCP 协议并且端口为3306的文件

使用 `lsof -i TCP:1-1024` 列出使用了TCP协议并且端口范围为 1 到 1024 的文件



kill -9 `lsof -t -u tt`

上述命令中，`lsof -u tt` 是列出`tt`用户所有打开的文件，加上 `-t` 选项之后表示结果只列出PID列，也就是进程ID列，其他列都忽略，前面的 `kill -9` 表示强制结束指定的进程ID



`tail -1000f logs/spring.log`





# 2024/6/13



k8s命令：

```sh
kfac logs -f pie-admin-7db759ddd-58ksf --tail 500
```

> `kfac`：





连接postgresql

```sh
kinfra get po  |grep postgres

kinfra exec -it  engine-postgres-5c7f79855b-pw4hh  /bin/bash

 psql -U postgres -d pie_user
 # 这里-U是需要连接的数据库用户，-d是数据库名字
 
 ple_user=# // 出现这个代表连接成功
```

> 1.先连接数据库，执行sql(ip:30811 postgres/123456)
> pie_user数据库
>
> `kinfra`：



```
要重启一下server那边的web-server

kser get po | grep web-server

kser delete po web-server-xxxxxxx
```



# 2024/6/28

日志管理系统，用户角色权限**RBAC**模式

![image-20240628110945338](assets/image-20240628110945338.png)

**用户表**: `sys_user`

| 属性        | 类型         | 默认值   | 注释                        |
| ----------- | ------------ | -------- | --------------------------- |
| id          | bigint(20)   | 自增     | 会员id                      |
| username    | varchar(20)  | ''       | 用户名                      |
| password    | varchar(32)  | ''       | 密码                        |
| name        | varchar(50)  | NULL     | 姓名                        |
| phone       | varchar(11)  | NULL     | 手机号码                    |
| avatar      | varchar(255) | NULL     | 头像URL                     |
| description | varchar(255) | NULL     | 描述                        |
| status      | tinyint(4)   | 1        | 状态（1：正常 0：停用）     |
| create_time | timestamp    | 当前时间 | 创建时间                    |
| update_time | timestamp    | 当前时间 | 更新时间，更新时自动刷新    |
| is_deleted  | tinyint(4)   | 0        | 删除标记（0:不可用 1:可用） |

**用户角色关系表**: `sys_user_role`

| 属性        | 类型       | 默认值   | 注释                        |
| ----------- | ---------- | -------- | --------------------------- |
| id          | bigint(20) | 自增     | 主键id                      |
| role_id     | bigint(20) | 0        | 角色id                      |
| user_id     | bigint(20) | 0        | 用户id                      |
| create_time | timestamp  | 当前时间 | 创建时间                    |
| update_time | timestamp  | 当前时间 | 更新时间，更新时自动刷新    |
| is_deleted  | tinyint(4) | 0        | 删除标记（0:不可用 1:可用） |

**角色表**: `sys_role`

| 属性        | 类型         | 默认值            | 注释                        |
| ----------- | ------------ | ----------------- | --------------------------- |
| id          | bigint(20)   | 自增              | 角色id                      |
| role_name   | varchar(20)  | ''                | 角色名称                    |
| role_code   | varchar(20)  | NULL              | 角色编码                    |
| description | varchar(255) | NULL              | 描述                        |
| create_time | timestamp    | CURRENT_TIMESTAMP | 创建时间                    |
| update_time | timestamp    | CURRENT_TIMESTAMP | 更新时间，更新时自动刷新    |
| is_deleted  | tinyint(4)   | 0                 | 删除标记（0:不可用 1:可用） |



**角色权限关系表**: `sys_role_permission`

| 属性        | 类型       | 默认值   | 注释                                             |
| ----------- | ---------- | -------- | ------------------------------------------------ |
| id          | bigint(20) | 自增     | 记录ID                                           |
| role_id     | bigint(20) | 0        | 角色ID                                           |
| menu_id     | bigint(20) | 0        | 菜单ID                                           |
| create_time | timestamp  | 当前时间 | 创建时间                                         |
| update_time | timestamp  | 当前时间 | 更新时间，更新时自动刷新                         |
| is_deleted  | tinyint(4) | 0        | 删除标记（0:不可用 1:可用）                      |
| is_half     | tinyint(4) | NULL     | 是否为半权限标志（可选字段，具体意义视业务而定） |

**权限表**: `sys_permission`

| 属性        | 类型         | 默认值   | 注释                        |
| ----------- | ------------ | -------- | --------------------------- |
| id          | bigint(20)   | 自增     | 编号                        |
| parent_id   | bigint(20)   | 0        | 所属上级                    |
| title       | varchar(20)  | ''       | 权限标题                    |
| component   | varchar(100) | NULL     | 组件名称                    |
| sort_value  | int(11)      | 1        | 排序                        |
| status      | tinyint(4)   | 1        | 状态(0:禁止,1:正常)         |
| create_time | timestamp    | 当前时间 | 创建时间                    |
| update_time | timestamp    | 当前时间 | 更新时间，更新时自动刷新    |
| is_deleted  | tinyint(4)   | 0        | 删除标记（0:不可用 1:可用） |



更好的设计

| 模块名 | 菜单名 | 权限名                 | 模块代码 | 菜单代码 | 权限代码   |
| ------ | ------ | ---------------------- | -------- | -------- | ---------- |
| 模块1  |        | 浏览、编辑、删除、下载 | M1       |          | V, E, D, L |
| 模块3  |        | 浏览、编辑、删除、下载 | M3       |          | V, E, D, L |
| 模块2  | 菜单1  | 浏览、编辑、删除、下载 | M2       | C1       | V, E, D, L |
| 模块2  | 菜单2  | 浏览、编辑、删除、下载 | M2       | C2       | V, E, D, L |

此表格清晰地列出了每个模块及其下菜单的权限分配情况，包括浏览(View, V)、编辑(Edit, E)、删除(Delete, D)和下载(Download, L)等权限。





sql语句

需求1：查询id为1的用户所具有的角色数据

```sql
SELECT sr.id,sr.role_code,sr.role_name FROM sys_role sr 
INNER JOIN sys_user_role sur ON sr.id=sur.role_id 
WHERE sur.user_id=1
```

需求2：查询id为1的用户所具有的菜单数据

```sql
SELECT DISTINCT m.* FROM sys_menu m 
INNER JOIN sys_role_menu rm ON rm.menu_id = m.id 
INNER JOIN sys_user_role ur ON ur.role_id = rm.role_id 
WHERE ur.user_id=1
```





# 2024/7/2

## 底图服务

https://www.bilibili.com/read/mobile?id=4230411

### SHP和GeoTIFF文件

- **SHP文件（Shapefile）** Shapefile是一种流行的地理信息系统（GIS）矢量数据格式，主要由三个文件组成：.shp（几何数据）、.shx（索引数据）和.dbf（属性数据）。它们一起使用来存储地理要素（如点、线和多边形）及其属性。
- **GeoTIFF文件** GeoTIFF是一种包含地理空间元数据的TIFF图像格式，用于存储栅格数据。它可以存储与图像关联的地理坐标信息，使其能够在GIS软件中正确地显示和处理。

### 发布为服务

将SHP或GeoTIFF数据发布为服务通常涉及以下步骤：

1. **数据准备** 确保SHP或GeoTIFF文件格式正确，并包含所需的空间参考信息和属性数据。
2. **选择发布平台** 选择一个地理空间服务器或平台，如GeoServer、ArcGIS Server或QGIS Server。这些平台提供了将地理空间数据发布为网络服务的工具和接口。
3. **配置服务** 在选择的平台上配置服务，包括指定数据源、定义服务类型（如WMS、WFS或WMTS），并设置相关参数（如图层样式、投影等）。
4. **发布服务** 将配置好的地理空间数据发布到服务器，使其能够通过网络进行访问。发布后，服务将生成一个URL，客户端可以通过该URL访问地理数据。
5. **访问服务** 客户端应用（如GIS软件、Web地图应用或自定义应用）可以通过网络协议（如WMS、WFS或WMTS）访问发布的服务，进行数据的查看、查询和分析。

### 服务类型

- **WMS（Web Map Service）** 一种标准协议，用于请求和显示地图图像。客户端可以通过WMS请求特定地理范围和图层的地图图像。
- **WFS（Web Feature Service）** 一种标准协议，用于请求和操作地理要素。WFS提供对矢量数据的访问和操作，如查询、插入、更新和删除要素。
- **WMTS（Web Map Tile Service）** 一种标准协议，用于请求和显示瓦片地图。WMTS将地图切割成固定大小的瓦片，并通过URL请求这些瓦片进行快速显示。

### 例子

- **GeoServer发布SHP数据为WMS服务**
  1. 在GeoServer管理界面添加一个新的数据存储，选择Shapefile并上传你的SHP文件。
  2. 创建一个新的图层，选择刚才上传的数据存储。
  3. 配置图层样式和其他参数。
  4. 发布图层，生成WMS服务的URL。
  5. 客户端可以通过WMS URL请求和显示地图图层。
- **ArcGIS Server发布GeoTIFF数据为WMS服务**
  1. 在ArcGIS Pro或ArcMap中加载你的GeoTIFF文件。
  2. 使用ArcGIS Server发布工具，将图层发布为地图服务。
  3. 配置服务参数和权限。
  4. 发布服务，生成WMS服务的URL。
  5. 客户端可以通过WMS URL访问和显示栅格数据。



# 2024/7/23

数据库服务器207 和应用服务器 209

## 部署到KingbaseES

进入`/data/kingbase/Server/bin`

```sh
./ksql -p 54321 -U system test
```

```sql
进入数据库
psql -U system -d test
# 数据库账号密码
system SystemDBA
```

导入数据库：

```sh
\i sql路径
```



`/data/software`

```sh
# 应用更新就是用新的jar包替换之前部署的jar，然后执行停止服务
./shutdown.sh
# 启动服务
./startup.sh
# 查看启动日志
tail -f logs/spring.log
```



## KingbaseES创建一个只读账户

[KingbaseES 创建只读（read_only）用户 - KINGBASE研究院 - 博客园 (cnblogs.com)](https://www.cnblogs.com/kingbase/p/15990843.html)
